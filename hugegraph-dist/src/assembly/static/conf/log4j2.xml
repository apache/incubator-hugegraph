<?xml version="1.0" encoding="UTF-8"?>

<!-- Config will be auto loaded every 60s -->
<configuration status="error" monitorInterval="60">
    <properties>
        <property name="LOG_PATH">logs</property>
        <property name="FILE_NAME">hugegraph-server</property>
    </properties>

    <appenders>
        <Console name="console" target="SYSTEM_OUT">
            <ThresholdFilter level="INFO" onMatch="ACCEPT" onMismatch="DENY"/>
            <PatternLayout pattern="%-d{yyyy-MM-dd HH:mm:ss} [%t] [%p] %c{1.} - %m%n"/>
        </Console>

        <!-- Normal server log config -->
        <RollingRandomAccessFile name="file" fileName="${LOG_PATH}/${FILE_NAME}.log"
            filePattern="${LOG_PATH}/$${date:yyyy-MM}/${FILE_NAME}-%d{yyyy-MM-dd}-%i.log"
            bufferedIO="true" bufferSize="524288" immediateFlush="false">
            <ThresholdFilter level="TRACE" onMatch="ACCEPT" onMismatch="DENY"/>
            <PatternLayout pattern="%-d{yyyy-MM-dd HH:mm:ss} [%t] [%p] %c{1.} - %m%n"/>
            <!--JsonLayout compact="true" eventEol="true" complete="true" locationINFO="true">
                <KeyValuePair key="timestamp" value="$${date:yyyy-MM-dd HH:mm:ss.SSS}"/>
            </JsonLayout-->
            <!-- Trigger after exceeding 1day or 50MB -->
            <Policies>
                <SizeBasedTriggeringPolicy size="50MB"/>
                <TimeBasedTriggeringPolicy interval="1" modulate="true" />
            </Policies>
            <!-- Keep 5 files per day & auto delete after over 2GB or 100 files -->
            <DefaultRolloverStrategy max="nomax">
                <Delete basePath="${LOG_PATH}" maxDepth="2">
                    <IfFileName glob="*/*.log"/>
                    <!-- Limit log amount & size -->
                    <IfAny>
                        <IfAccumulatedFileSize exceeds="2GB" />
                        <IfAccumulatedFileCount exceeds="100" />
                    </IfAny>
                </Delete>
            </DefaultRolloverStrategy>
        </RollingRandomAccessFile>

        <!-- Separate & compress audit log, buffer size is 512KB -->
        <RollingRandomAccessFile name="audit" fileName="${LOG_PATH}/audit-${FILE_NAME}.log"
            filePattern="${LOG_PATH}/$${date:yyyy-MM}/audit-${FILE_NAME}-%d{yyyy-MM-dd-HH}-%i.gz"
            bufferedIO="true" bufferSize="524288" immediateFlush="false">
            <ThresholdFilter level="TRACE" onMatch="ACCEPT" onMismatch="DENY"/>
            <!-- Use simple format for audit log to speed up -->
            <PatternLayout pattern="%m%n" />
            <!-- Use simple format for audit log to speed up -->
            <!--JsonLayout compact="true" eventEol="true" >
                <KeyValuePair key="timestamp" value="$${date:yyyy-MM-dd HH:mm:ss.SSS}"/>
            </JsonLayout-->
            <!-- Trigger after exceeding 1hour or 500MB -->
            <Policies>
                <SizeBasedTriggeringPolicy size="512MB"/>
                <TimeBasedTriggeringPolicy interval="1" modulate="true" />
            </Policies>
            <!-- Keep 2 files per hour & auto delete [after 60 days] or [over 5GB or 500 files] -->
            <DefaultRolloverStrategy max="16">
                <Delete basePath="${LOG_PATH}" maxDepth="2">
                    <IfFileName glob="*/*.gz"/>
                    <IfLastModified age="60d"/>
                    <IfAny>
                        <IfAccumulatedFileSize exceeds="5GB" />
                        <IfAccumulatedFileCount exceeds="500" />
                    </IfAny>
                </Delete>
            </DefaultRolloverStrategy>
        </RollingRandomAccessFile>
    </appenders>

    <loggers>
        <root level="INFO">
            <appender-ref ref="file"/>
        </root>
        <logger name="org.apache.hadoop" level="INFO" additivity="false">
            <appender-ref ref="file"/>
        </logger>
        <logger name="org.apache.zookeeper" level="WARN" additivity="false">
            <appender-ref ref="file"/>
        </logger>
        <logger name="com.datastax.driver" level="WARN" additivity="false">
            <appender-ref ref="file"/>
        </logger>
        <logger name="com.alipay.sofa" level="WARN" additivity="false">
            <appender-ref ref="file"/>
        </logger>
        <logger name="io.netty" level="INFO" additivity="false">
            <appender-ref ref="file"/>
        </logger>
        <logger name="org.apache.commons" level="INFO" additivity="false">
            <appender-ref ref="file"/>
        </logger>
        <!-- Use mixed async way to output logs -->
        <AsyncLogger name="com.baidu.hugegraph" level="INFO" additivity="false">
            <appender-ref ref="file"/>
        </AsyncLogger>
        <AsyncLogger name="com.baidu.hugegraph" level="INFO" additivity="false">
            <appender-ref ref="audit"/>
        </AsyncLogger>
        <AsyncLogger name="com.baidu.hugegraph.auth" level="INFO" additivity="false">
            <appender-ref ref="file"/>
        </AsyncLogger>
        <AsyncLogger name="com.baidu.hugegraph.api.filter.AuthenticationFilter" level="INFO" additivity="false">
            <appender-ref ref="file"/>
        </AsyncLogger>
        <AsyncLogger name="audit-log-appender" level="INFO" additivity="false">
            <appender-ref ref="audit" />
        </AsyncLogger>
    </loggers>
</configuration>
